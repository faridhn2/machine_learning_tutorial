{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyML:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.is_normal = False\n",
    "        self.predictions = []\n",
    "        \n",
    "        file_path = input('Please enter csv file path')\n",
    "        self.load_data(file_path)\n",
    "        \n",
    "        self.add_models()\n",
    "        self.call_pca_normalization()\n",
    "        self.split_data()\n",
    "        self.train()\n",
    "        self._test()\n",
    "               \n",
    "    def load_data(self,file_name):\n",
    "        self.data = pd.read_csv(file_name)\n",
    "        \n",
    "        while True:\n",
    "            self.data.info()\n",
    "            \n",
    "            y_columns = input(\"Enter your y columns: \").replace(\n",
    "                ' ','').split(\",\")\n",
    "            \n",
    "            if not set(y_columns).issubset(set(self.data.columns)):\n",
    "                continue\n",
    "            \n",
    "            self.y = self.data[y_columns]\n",
    "            \n",
    "            break\n",
    "        clear_output()\n",
    "        \n",
    "        while True:\n",
    "            self.data.info()\n",
    "            \n",
    "            drop_columns = input(\"Enter Drop columns: \").replace(\n",
    "                ' ','').split(\",\")\n",
    "            print('drop_columns: ',drop_columns)\n",
    "            if  drop_columns == ['']:\n",
    "                break\n",
    "            \n",
    "            if not set(drop_columns).issubset(set(self.data.columns)):\n",
    "                continue\n",
    "            \n",
    "            self.data = self.data.drop(drop_columns,axis=1)\n",
    "            \n",
    "            break\n",
    "        clear_output()\n",
    "        self.data.info()\n",
    "        while True:\n",
    "            self.data.info()\n",
    "            \n",
    "            dummies_columns = input(\"Enter Dummeis columns: \").replace(\n",
    "                ' ','').split(\",\")\n",
    "            \n",
    "            if dummies_columns == ['']:\n",
    "                break\n",
    "            \n",
    "            if not set(dummies_columns).issubset(set(self.data.columns)):\n",
    "                continue\n",
    "            \n",
    "            for dum_col in dummies_columns:\n",
    "                dummies_df = pd.get_dummies(self.data[dum_col],\n",
    "                                            drop_first=True,dtype=int)\n",
    "                \n",
    "                self.data.drop(dum_col,axis=1,inplace=True)\n",
    "                self.data = pd.concat([self.data,dummies_df],axis=1)\n",
    "                \n",
    "            \n",
    "            \n",
    "            break\n",
    "            \n",
    "        clear_output()\n",
    "        self.x = self.data.drop(y_columns,axis=1)\n",
    "        self.data.info()    \n",
    "        \n",
    "    \n",
    "    def add_models(self):\n",
    "        lookup_models = {'knn':{'requirement':{'k':None},\n",
    "                                'SKmodel':KNeighborsClassifier}\n",
    "                         ,'kmeans':{'requirement':{'k':None},\n",
    "                                   'SKmodel':KMeans}\n",
    "                         ,'logistic':{'SKmodel':LogisticRegression}\n",
    "                         ,'dtree':{'SKmodel':DecisionTreeClassifier}\n",
    "                         ,'RFC':{'requirement':{'n_estimators':None},\n",
    "                                'SKmodel':RandomForestClassifier}\n",
    "                         ,'svm':{'SKmodel':SVC}}\n",
    "        \n",
    "        model_name = ''\n",
    "        \n",
    "        while  model_name != 'ok':\n",
    "            print(lookup_models.keys())\n",
    "            \n",
    "            model_name = input('your model? ')\n",
    "            \n",
    "            if not model_name in list(lookup_models.keys()):\n",
    "                continue\n",
    "            \n",
    "            if 'requirement' in lookup_models[model_name]:\n",
    "                args = []\n",
    "                for key in lookup_models[model_name]['requirement']:\n",
    "                    val  = int(input(f'value of {key} ? '))\n",
    "                    lookup_models[model_name]['requirement'][key]=val\n",
    "                    args.append(val)\n",
    "                model = lookup_models[model_name]['SKmodel'](*args)\n",
    "                \n",
    "            else:\n",
    "                model = lookup_models[model_name]['SKmodel']()\n",
    "            \n",
    "            self.models.append({model_name:model})\n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "    def _normalization(self):\n",
    "        # mode=['Standard','MinMax']\n",
    "        mode = {\"Standard\":StandardScaler,'MinMax':MinMaxScaler}\n",
    "        \n",
    "        while True:\n",
    "            answer = input(\"normalize?['Standard','MinMax','n']\")\n",
    "            print(answer)\n",
    "            print(mode)\n",
    "            if answer == \"n\":\n",
    "                break\n",
    "            elif answer in mode:\n",
    "                scaler = mode[answer]()\n",
    "                self.x = scaler.fit_transform(self.x)\n",
    "                self.is_normal = True\n",
    "            \n",
    "                break\n",
    "        \n",
    "        \n",
    "     \n",
    "    def _pca(self):\n",
    "        while True:\n",
    "            try:\n",
    "                n_component = int(input('n_component: / (0) == no pca'))\n",
    "                if n_component == 0:\n",
    "                    break\n",
    "                pca = PCA(n_component)\n",
    "                self.x = pca.fit_transform(self.x)\n",
    "                break                \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        \n",
    "    def call_pca_normalization(self):\n",
    "        self._normalization()\n",
    "        if self.is_normal:\n",
    "            self._pca()\n",
    "        \n",
    "    def split_data(self):\n",
    "        while True:\n",
    "            try:\n",
    "                test_size = float(input('test_size?'))\n",
    "                self.X_train, self.X_test, self.y_train,self.y_test = train_test_split(\n",
    "                self.x,self.y, test_size=test_size,random_state=101)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        for d_model in self.models:\n",
    "            try:\n",
    "                model = list(d_model.values())[0]\n",
    "                model.fit(self.X_train, self.y_train.values.ravel())\n",
    "            except:\n",
    "                pass              \n",
    "        \n",
    "    \n",
    "    def _test(self):\n",
    "        \n",
    "        for d_model in self.models:\n",
    "            try:\n",
    "                model = list(d_model.values())[0]\n",
    "                preds = model.predict(self.X_test)\n",
    "                d = {list(d_model.keys())[0]:preds}\n",
    "                self.predictions.append(d)\n",
    "            except:\n",
    "                pass    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def result(self):\n",
    "        acc = []\n",
    "        model_name = []\n",
    "        for preds in self.predictions:\n",
    "            print(\"Model Name: \" + list(preds.keys())[0])\n",
    "            print(metrics.classification_report(self.y_test.to_numpy().ravel(),\n",
    "                                         list(preds.values())[0]))\n",
    "            p = metrics.classification_report(self.y_test.to_numpy().ravel(),\n",
    "                                 list(preds.values())[0])\n",
    "            print(\"*\"*50)\n",
    "                  \n",
    "            report = metrics.classification_report(my_model.y_test.to_numpy().ravel(),\n",
    "                                 list(preds.values())[0], output_dict  = True)\n",
    "            acc.append(report[\"accuracy\"])\n",
    "            model_name.append(list(preds.keys())[0])\n",
    "        \n",
    "        sns.barplot(model_name, acc)\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
